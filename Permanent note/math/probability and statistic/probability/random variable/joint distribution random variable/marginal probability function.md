​ #probability/joint_distribution_random_variable #todo 

Let $Y_1$ and $Y_2$ be jointly discrete random variables with probability function $p(y_1,y_2)$. Then the marginal probability functions of $Y_1$ and $Y_2$ are :

1. $p_1(y_1) = \sum_{all y_2}p(y_1,y_2)$ ​
2. $p_2(y_2) = \sum_{all y_1}p(y_1,y_2)$ ​

# marginal probability function of a joint distribution random variable and the probability distribution of a random variable[^1]

I think they are talking about the same thing. ~~Considering drawing a ball from a bag consisting of red blue and white balls. Let ​~~​~~$XX﻿$~~​~~​ denote the number of red ball drawn, ​~~​~~$ YY﻿$~~​~~​ for blue.  ​~~​~~$ P\{X, Y\} = \frac{C^n_xC^m_yC^a_{t-x-y}}{C^{n+m+a}_t}P{X, Y}=Ctn+m+aCxnCymCt−x−ya﻿$~~​~~, ​~~​~~$ P\{X\}P{X}﻿$~~​~~​ is the sum of all possible values of ​~~​~~$ YY﻿$~~​~~.~~ We can consider the joint distribution distribution as the intersection of two random variables. Using Baye's rule we can predict that $P(B) = P(B,A_1) + P(B,A_2) + ... + P(B,A_n)$ 

‍

1. [Project - mathematical s...](lt://open/a5WmnTLLWUCIS3RgBdrVRQ)
2. ‍
