#probability/joint_distribution_random_variable 

Joint distribution random variable is a structure concerning two or more random variables on the same sample space[^1]. They can be both discrete random variable[^2] or Continuous random variable[^8]. It can be viewed as a function of random variables. We can define joint cumulative distribution function[^31] and conditional distribution function[^32] for both discrete and continuous types.

# discrete type

We can define joint probability mass function[^34] for discrete types. Based on the function defined above, we can define marginal probability function[^35]for measuring the probability of a single random variable[^29] and conditional discrete probability function[^36] for characterizing the relationship between these two random variables. Expected value of these two joint random variables can be also defined to predict the outcome of the event. If they are Independent joint random variable[^37] , thus they need to satisfy the properties listed. If they are dependent, we use covariance[^27] to determine the degree.

# continuous type 

We define joint density function[^33]s for continuous types. Then it is easy to define marginal density function[^38] for a single random variable. We use conditional density function[^39] to show the probability of a random variable with the existence of another random variable. Expected value of these two joint random variables can be also defined to predict the outcome of the event. If they are Independent joint random variable[^37] , thus they need to satisfy the properties listed. If they are dependent, we use covariance[^27] to determine the degree.

# 

‍

‍

‍

1. [Rice_2007_Mathematical statistics and data analysis - Excerpt of: Rice_2007_Mathematical statistics and data analysis, p88](lt://open/-RENpdgJWE2pynr8HSTbuQ)
2. ‍
