#probability 
The variance of a sample of measurements  $y_1,y_2,y_3,...,y_n$ is the sum of the square of the differences between the measurements and their [[mean]], divided by $n-1$. Symbolically,  
$s^{2} = \frac{1}{n-1}\sum_{n}(y_i-\bar{y})^2$  

#### sum of squared deviation(SSD)

$\sum_{n}(y_i-\bar{y})^2$  
[[population]] variance is $\sigma^2 = \frac{1}{n}\sum_{n}(y_i-\mu)^2$  

## understanding of variance

## variance of of random variables

The variance of a random variable can be calculated using the equation $V[X] = E[X^2] - (E[X])^2$ $E[X]$ is the [[expected value]]of the random variable $X$  

### variance of a function of a random variable

1. $V[ax +b] = a^2V[x]$
2. If $X$ and $Y$ are random variables, then $\sigma^2(aX +bY) = a^2\sigma^2(X) + b^2\sigma^2(Y) + 2ab\sigma_{XY}$ where $\sigma_{XY}$ is the [[covariance]] of $X$ and $Y$ 

    proof: #todo
3. If $X$ and $Y$ are independent random variables, then $\sigma^2(aX +bY) =a^2\sigma^2(X) + b^2\sigma^2(Y)$

### variance of a function of random variables

#todo

‍

‍

# reference
#todo 