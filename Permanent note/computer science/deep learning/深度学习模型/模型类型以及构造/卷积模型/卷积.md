---

aliases: [cross-correlation]

---

# 源流

对于MLP，所需参数为像素数量$*$隐藏层层数$*$对应隐藏神经元个数
参数过多

# 引入

图片模式识别的两个原则

## 平移不变性

不同的位置，模式不变

## 局部性

判断一个模式需要的信息应该在一个小范围内

# 数学模型

## 1.

输入输出变成矩阵

## 2.

权重变成4-D张量

## 3.对于全连接层

$h_{i,j} - \sum_{k,l}w_{i,j,k,l}x_{k,l} = \sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}$
V 是 W的重新索引$v_{i,j,a,b} = w_{i,j,i+a,j+b}$

## 4.二维交叉相关

### 根据平移不变性

x的平移导致h平移，对于v，我们认为v不应该依赖于(i,j)
理由：<font color="00FF00" size="3">对于一个图片中的某一特征，我们希望它对于不同的坐标（a，b），乘以对应的卷积核之后得到的输出应该一致</font>
所以$v_{i,j,a,b} = v_{a,b}$
$h_{i,j} = \sum _{a,b}v_{a,b}x_{i+a,j+b}$

### 根据局部性

评估$h_{i,j}S$时，我们不应该用远离$x_{i,j}$的参数
方法：
当$|a|,|b| \geq \delta$,$v_{a,b} = 0$
$\to$ $h_{i,j} = \sum^{\delta}_{a=-\delta}\sum^{\delta}_{b=-\delta}v_{a,b}x_{i+a,j+b}$

### 交叉相关和卷积

#### 交叉相关（实际使用）

$h_{i,j} = \sum^{h}_{a=1}\sum^{w}_{b=1}v_{a,b}x_{i+a,j+b}$

##### 代码实现

	def corr2、(X, K): #@save """计算⼆维互相关运算"""
		h, w = K.shape
		#构建输出矩阵Y
		Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
		#计算Y每个entry的值
		for i in range(Y.shape[0]):
			for j in range(Y.shape[1]):
				Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
		return Y

#### 卷积

$h_{i,j} = \sum^{h}_{a=1}\sum^{w}_{b=1}v_{-a,-b}x_{i+a,j+b}$

## 卷积层

### 一维卷积层

$y_i = \sum^h_{a=1} w_a x_{i+a}$

#### 作用

文本、语言、时序序列

#### 模型构造

### 二维卷积层

输入$X$ : $n_h \times n_w$
核$W$:$k_h \times k_w$
偏差$b \in R$
输出$Y$ :$(n_h -k_h +1) \times (n_w - k _w +1)$
$Y = X \cdot W + b$
(W 和 b 是参数）

#### 模型构造

##### 自己定义

	class Conv2D(nn.Module):
		def __init__(self, kernel_size):
			super().__init__()
			self.weight = nn.Parameter(torch.rand(kernel_size))
			self.bias = nn.Parameter(torch.zeros(1))
		def forward(self, x): return corr2d(x, self.weight) + self.bias

##### pytorch 实现

	nn.Conv2d( , ,kernel_size = (m,n),bias = True/False)

#### 1 * 1 卷积层

不识别空间模式，只融合通道
相当于输入形状为$n_hn_w \times c_i$，权重为$c_o \times c_i$ 的全连接层

### 三位卷积层

$y_{i,j,k} = \sum^h_{a=1}\sum^w_{b=1}\sum^d_{c=1} w_{a,b,c} x_{i+a,j+b,k+c}$

#### 作用

视频、医学图像、气象地图
